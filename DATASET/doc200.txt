To control the spread of Corona Virus Disease , screening large numbers of suspected cases for appropriate quarantine and treatment is a priority.
Pathogenic laboratory testing is the diagnostic gold standard but it is time consuming with significant false negative results. Fast and accurate diagnostic methods are urgently needed to combat the disease. Based on COVID-19 radiographical changes in CT images, we aimed to develop a deep learning method that could extract COVID-19's graphical features in order to provide a clinical diagnosis ahead of the pathogenic test, thus saving critical time for disease control.
Methodsï¼šWe collected 1,119 CT images of pathogen-confirmed COVID-19 cases along with those previously diagnosed with typical viral pneumonia. We modified the Inception transfer-learning model to establish the algorithm, followed by internal and external validation.
The internal validation achieved a total accuracy of 89.5% with specificity of 0.88 and sensitivity of 0.87. The external testing dataset showed a total accuracy of 79.3% with specificity of 0.83 and sensitivity of 0.67. In addition, in 54 COVID-19 images that first two nucleic acid test results were negative, 46 were predicted as COVID-19 positive by the algorithm, with the accuracy of 85.2%.
These results demonstrate the proof-of-principle for using artificial intelligence to extract radiological features for timely and accurate COVID-19 diagnosis.

The outbreak of atypical and person-to-person transmissible pneumonia caused by the severe acute respiratory syndrome coronavirus 2 (SARS-COV-2, also known as 2019-nCov) has caused a global alarm. There have been more than 100,000 confirmed cases of the Corona Virus Disease in the world, as of May 8, 2020 . According to the WHO, 16-21% of people with the virus in China have become severely ill with a 2-3% mortality rate. With the most recent estimated viral reproduction number (R0), the average number of other people that an infected individual will transmit the virus to in a completely non-immune population, stands at about 3.77 [1] , indicating that a rapid spread of the disease is imminent. Therefore, it is crucial to identify infected individuals as early as possible for quarantine and treatment procedures.
The diagnosis of COVID-19 relies on the following criteria: clinical symptoms, epidemiological history and positive CT images, as well as positive pathogenic testing. The clinical characteristics of COVID-19 include respiratory symptoms, fever, cough, dyspna, and pneumonia [2] [3] [4] [5] . However, these symptoms are nonspecific, as there are isolated cases where, for example, in an asymptomatic infected family a chest CT scan revealed pneumonia and the pathogenic test for the virus came back positive. Once someone is identified as a PUI (person under investigation), lower respiratory specimens, such as bronchoalveolar lavage, tracheal aspirate or sputum, will be collected for pathogenic testing. This laboratory technology is based on real-time RT-PCR All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint and sequencing of nucleic acid from the virus [6, 7] . Since the beginning of the outbreak, the efficiency of nucleic acid testing has been dependent on several rate-limiting factors, including availability and quantity of the testing kits in the affected area. More importantly, the quality, stability and reproducibility of the detection kits are questionable. The impact of methodology, disease stages, specimen collection methods, nucleic acid extraction methods, and the amplification system are all determinant factors for the accuracy of test results.
Conservative estimates of the detection rate of nucleic acid are low (between 30-50%) [6, 7, 8] , and tests need to be repeated several times in many cases before they can be confirmed.
Radiological imaging is also a major diagnostic tool for COVID-19. The majority of COVID-19 cases have similar features on CT images including ground-glass opacities in the early stage and pulmonary consolidation in the late stage. There is also sometimes a rounded morphology and a peripheral lung distribution [5, 9] . Although typical CT images may help early screening of suspected cases, the images of various viral pneumonias are similar and they overlap with other infectious and inflammatory lung diseases. Therefore, it is difficult for radiologists to distinguish COVID-19 from other viral pneumonias.
Artificial Intelligence involving medical imaging deep-learning systems has been developed in image feature extraction, including shape and spatial relation features. Specifically, Convolutional Neural Network (CNN) has been proven in feature extraction and learning. CNN was used to enhance low-light All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint images from high-speed video endoscopy with the limited training data being just 55 videos [10] . Also, CNN has been applied to identify the nature of pulmonary nodules via CT images, the diagnosis of pediatric pneumonia via chest X-ray images, automated precising and labeling of polyps during colonoscopic videos, cystoscopic image recognition extraction from videos [11] [12] [13] [14] .
There are a number of features for identifying viral pathogens on the basis of imaging patterns, which are associated with their specific pathogenesis [15] .
The hallmarks of COVID-19 are bilateral distribution of patchy shadows and ground glass opacity [2] . Based on this, we believed that CNN might help us identify unique features that might be difficult for visual recognition.
Hence, the purpose of our study was to evaluate the diagnostic performance of a deep learning algorithm using CT images to screen for COVID-19. To test this notion, we retrospectively enrolled 1,119 CT images of pathogen-confirmed COVID-19 cases along with previously diagnosed typical viral pneumonia. Our results reported below demonstrate the proof-of-principle using the deep learning method to extract radiological graphical features for COVID-19 diagnosis.
All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint
Retrospective collection of datasets.
We retrospectively collected CT images from 259 patients, in which the cohort includes 180 cases of typical viral pneumonia and the other 79 cases from three hospitals with confirmed nucleic acid testing of SARS-COV-2. In addition, we enrolled additional 15 COVID cases, in which first two nucleic acid tests were negative at initial diagnoses. Hospitals providing the images were Xi'an Jiaotong University First Affiliated Hospital, Nanchang University First Hospital and Xi'an No.8 Hospital of Xi'an Medical College. All CT images were de-identified before sending for analysis. This study is in compliance with the Institutional Review Board of each participating institutes. Informed consent was exempted by the IRB because of the retrospective nature of this study.
We sketched the region of interest (ROI) on the CT images based on the features of pneumonia, such as ground-glass opacity, mosaic sign and interlobular septal thickening. For a ROI, it is sized approximately from 395*223 to 636*533 pixels.
Our systematic pipeline for the prediction architecture is depicted in Figure   1 . The architecture consists of three main processes. 1) Extraction of ROI images and randomly selection of ROIs; 2) Training of the CNN model to extract features; 3) Classification model training of fully connected network and All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint prediction of multiple classifiers. We built a transfer learning neural network based on the Inception network. The entire neural network can be roughly divided into two parts: the first part used a pre-trained inception network to convert image data into one-dimensional feature vectors, and the second part used a fully connected network and the main role is for classification prediction.
We randomly selected 2-3 ROI images from each case to form a training dataset. The number of various types of pictures in the training set is equal, with a total number of 320. The remaining CT pictures of each case were used for internal validation. The model training was iterated 15,000 times with a step size of 0.01. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint areas as the two lung areas. 5) Take the smallest bounding rectangle of the lung area as the ROI frame and crop the original image to obtain the ROI images. Then we randomly selected delineated ROIs for classification model building.
We modified the typical Inception network, and fine-tuned the modified 
After generating the features, the final step was to classify the pneumonia based on those features. Ensembling of classifiers was used to improve the classification accuracy. In this study, we adopted end-to-end learning to make the model convergence.
We compared the classification performance using Accuracy, Sensitivity, Specificity, Area Under Curve (AUC), Positive predictive value (PPV), Negative predictive value (NPV), F1 score and Youden Index. TP and TN represent the All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint
In the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14. 
At the same time, we asked two skilled radiologists to assess the 745 images for a prediction. Radiologist 1 achieved the accuracy of 55.8% with sensitivity of 0.71 and specificity of 0.51, and Radiologist 2 achieved a similar accuracy of 55.4% with sensitivity of 0.73 and specificity of 0.50 ( Table 3) .
These results indicates that it is difficult for radiologists to make prediction of COVID-19 with eye recognition, further showing the advantage of the algorithm we developed.
Because high false negative results were frequently reported from nucleic acid testing, we aimed to test whether the algorithm could detect COVID-19 when the pathogenic test came negative. To achieve this goal, we enrolled additional 15 COVID-19 cases, in which initial two nucleic acid tests came All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint negative and for the third test they became positive. These CT results were taken on the same day of the nucleic acid tests ( Figure 5) . Interestingly, we found that, 46 out of the 54 images when nucleic acid test results were negative were predicted as COVID-19 positive by the algorithm, with the accuracy of 85.2%. These results indicate that the algorithm can predict COVID-19 status ahead of a pathogenic test.
All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint
Timely diagnosis and triaging of PUIs are crucial for the control of emerging infectious diseases such as the current COVID-19. Due to the limitation of nucleic acid -based laboratory testing, there is an urgent need to look for fast alternative methods that can be used by front-line health care personals for quickly and accurately diagnosing the disease. In the present study, we have developed an AI program by analyzing representative CT images using a deep learning method. This is a retrospective, multicohort, diagnostic study using our modified Inception migration neuro network, which has achieved an overall 89.5% accuracy. Moreover, the high performance of the deep learning model we developed in this study was tested using external samples with 79.3% accuracy. More importantly, as a screening method, our model achieved a relative high sensitivity, 0.88 and 0.83 on internal and external datasets, respectively. During current COVID-19 outbreaks and possible pandemics, the CNN model can potentially serve as a powerful tool for COVID-19 screening.
We compared the performance of our model with that of two skilled radiologists, and our model has shown much higher accuracy and sensitivity.
These findings have demonstrated the proof-of-principle that deep learning can extract CT image features of COVID-19 for diagnostic purposes. Using the supercomputer system, the time for each case takes only about 10 seconds, and it can be performed remotely via a shared public platform. Therefore, All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint further developing this system can significantly shorten the diagnosis time for disease control. Our study represents the first study to apply artificial intelligence technologies to CT images for effectively screening for COVID-19.
The gold standard for COVID-19 diagnosis has been nucleic acid based detection for the existence of specific sequences of the SARS-COV-2 gene.
While we still value the importance of nucleic acid detection in the diagnosis of SARS-COV-2 infection, we must also note that the high number of false negatives due to several factors such as methodological disadvantages, disease stages, and methods for specimen collection might delay diagnosis and disease control. Recent data have suggested that the accuracy of nucleic acid testing is only about 30-50% [6, 7, 8] . Using CT imaging feature extraction, we are able to achieve above 89.5% accuracy, significantly outplaying nucleic acid testing. More interestingly, testing CT images from COVID-19 patients when initial pathogenic testing came negative, our model has achieved the accuracy of 85.2% for correctly predicting COVID-19. This is critically important during the outbreak of COVID-19, when timely diagnosis is essence for disease control.
Although we are satisfied with the initial results, we believe that with more CT images included in the training, we will achieve higher accuracy. Therefore, further optimizing and testing this system is warranted. To achieve this, we have generated a webpage that licensed healthcare personnel can access to upload CT images for testing and validation. The webpage information is as All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint following: https://ai.nscc-tj.cn/thai/deploy/public/pneumonia_ct.
There are some limitations to our study. CT images represent a difficult classification task due to the relatively large number of variable objects, specifically the imaged areas outside the lungs that are irrelevant to the diagnosis of pneumonia [12] . In addition, the training data set is relatively small.
The performance of this system is expected to increase when the training volume is increased. It should also be noted that, the features of the CT images we analyzed were from patients with severe lung lesions at later stages of disease development. Although we have enrolled 15 cases of COVID patients for assessing the value of the algorithm for early diagnosis, larger numbers of database to associate this with the disease progress and all pathologic stages of COVID-19 is necessary to optimize the diagnostic system.
In future, we intend to link hierarchical features of CT images to features of other factors such as genetic, epidemiological and clinical information for multi-modeling analysis for an enhanced diagnosis. The artificial intelligence system developed in our study should significantly contribute to COVID-19 disease control by reducing the number of PUIs for timely quarantine and treatment.
All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint . All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint validation. The loss curve tends to be stable after descending, indicating that the training process converges All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint Figure 5 . Representative images from a COVID-19 patient with two negatively reported nucleic acid tests at earlier stages and one final positively reported test at a later stage. On the left, only one inflammatory lesion (blue arrow) can be seen near diaphragm. In the middle, lesions (yellow arrows) were found in two levels of images. On the right, the images were taken on the ninth day after admission. The inflammation continued to progress, extending to both lungs (red arrows), and the nucleic acid test became positive. All rights reserved. No reuse allowed without permission. the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint All rights reserved. No reuse allowed without permission.
the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
The copyright holder for this preprint (which was not peer-reviewed) is . https://doi.org/10.1101/2020.02.14.20023028 doi: medRxiv preprint 
